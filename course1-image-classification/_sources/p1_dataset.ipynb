{"cells":[{"cell_type":"markdown","metadata":{"id":"S3GLsdirSK43"},"source":["# Preparing an Image Dataset for Model Training\n","\n","**Goal:**\n","\n","- Implement a [map-style Dataset class](https://pytorch.org/docs/stable/data.html#map-style-datasets).\n","- Implement a [data loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) that directly feeds data into model training.\n","- Quality check your data, served through dataset class.\n","\n","**Acceptance criteria:**\n","\n","- The Dataset class should implement `__getitem__`  and `__len__` methods, where `__getitem__` should return a training example, which is a tuple of (image, label).\n","- The data loader should be iterable and returns batches of examples.\n","- In a notebook, present example images, labels and ensure correct shapes by visual inspection.\n","\n","**Resources**:\n","- Sample key: a notebook containing the keys of the exercises is attached [here](/p1_dataset_key).\n","\n","## Step 1: Create a Dataset class\n","\n","One of the first things you may need to do in a practical project is to create a custom dataset class. As a start, let us use CIFAR10 raw data as an example to create one. First, we need to download the data:\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8632,"status":"ok","timestamp":1660179290522,"user":{"displayName":"Zhangzhang Si","userId":"05784349039024700350"},"user_tz":300},"id":"GV8oooLDSK45","outputId":"e190d103-454e-46c8-81e9-292a14ac52cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-08-11 00:54:41--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n","Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 170498071 (163M) [application/x-gzip]\n","Saving to: ‘cifar-10-python.tar.gz’\n","\n","cifar-10-python.tar 100%[===================>] 162.60M  45.0MB/s    in 4.0s    \n","\n","2022-08-11 00:54:46 (40.6 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n","\n"]}],"source":["# Please makse sure to remove the exclamation mark if you run the commands in the terminal.\n","!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","!tar -xzf cifar-10-python.tar.gz"]},{"cell_type":"markdown","metadata":{"id":"9QS0Ag4TSK45"},"source":["Inspect the downloaded raw data and folder structure:"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145,"status":"ok","timestamp":1660179290648,"user":{"displayName":"Zhangzhang Si","userId":"05784349039024700350"},"user_tz":300},"id":"DRWi1qLgSK45","outputId":"7e6875e3-080a-4d40-bcde-3547b6ce5305"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 178M\n","-rw-r--r-- 1 2156 1103  88 Jun  4  2009 readme.html\n","-rw-r--r-- 1 2156 1103 158 Mar 31  2009 batches.meta\n","-rw-r--r-- 1 2156 1103 30M Mar 31  2009 data_batch_4\n","-rw-r--r-- 1 2156 1103 30M Mar 31  2009 data_batch_1\n","-rw-r--r-- 1 2156 1103 30M Mar 31  2009 data_batch_5\n","-rw-r--r-- 1 2156 1103 30M Mar 31  2009 data_batch_2\n","-rw-r--r-- 1 2156 1103 30M Mar 31  2009 data_batch_3\n","-rw-r--r-- 1 2156 1103 30M Mar 31  2009 test_batch\n"]}],"source":["!ls -lht cifar-10-batches-py/"]},{"cell_type":"markdown","metadata":{"id":"ymgP1nBBSK46"},"source":["The archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object.\n","\n","Loaded using the `unpickle` method provided below, each of the batch files contains a python dictionary with the following elements:\n","\n","*data* -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n","\n","*labels* -- a list of 10000 numbers in the range 0-9. Each number maps to a class label. For information about the 10 classes, please refer to the [CIFAR-10 website](https://www.cs.toronto.edu/~kriz/cifar.html).\n","\n","**Your task**: Fill in the missing code in the next cell, so that it can pass the test that follows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TopDglevSK46"},"outputs":[],"source":["import pickle\n","\n","\n","CLASSES = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\",\n","           \"horse\", \"ship\", \"truck\"]\n","\n","\n","def unpickle(file):\n","    with open(file, 'rb') as fo:\n","        dict = pickle.load(fo, encoding='bytes')\n","    # The keys of this dic: [b'batch_label', b'labels', b'data', b'filenames']\n","    return dict\n","\n","\n","def reshape_numpy_image(one_numpy_image):\n","    shape_with_channels_first = (3, 32, 32)  # (channels, height, width), channels first\n","    shape_with_channels_last = (32, 32, 3)  # (height, width, channels), channels last\n","    # TODO: in the next line, should we use shape_with_channels_first or shape_with_channels_last?\n","    #   It depends on how the numpy array in the raw data is stored. It is hard to know which\n","    #   whay is correct, without trying both and visualizing.\n","    return one_numpy_image.reshape(*shape_with_channels_last)\n","\n","\n","def print_and_visualize_data():\n","  data_dict = unpickle(\"cifar-10-batches-py/data_batch_1\")\n","  print(data_dict.keys())\n","  data = data_dict[b\"data\"]\n","  labels = data_dict[b\"labels\"]\n","  print(\"data:\", type(data), data.shape)\n","  print(\"labels:\", type(labels), len(labels))\n","\n","\n","  from matplotlib import pyplot as plt\n","  one_image = data[0, :]\n","  reshaped_image = reshape_numpy_image(one_image)\n","\n","  # imshow() requires the image to be in \"channels last\" format\n","  # So if the image is \"channels first\", transpose it.\n","  if reshaped_image.shape[0] == 3:\n","    reshaped_image = reshaped_image.transpose(1, 2, 0)\n","\n","  plt.imshow(reshaped_image)\n","  _ = plt.title(f\"{labels[0]}: {CLASSES[labels[0]]}\")\n","\n","\n","# Uncomment the following line to visualize data.\n","# print_and_visualize_data()"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":97,"status":"ok","timestamp":1660181888947,"user":{"displayName":"Zhangzhang Si","userId":"05784349039024700350"},"user_tz":300},"id":"fu2b4lncZp9F"},"outputs":[],"source":["import numpy as np\n","from typing import Tuple\n","\n","\n","class CustomDataset:\n","    def __init__(self, data_dir=\"cifar-10-batches-py\", train=True):\n","        # TODO: if train is True, load the training data (data_batch_1 through 5), otherwise load the validation data (test_data_batch).\n","        #\n","        # Some snippets that may be useful:\n","        #    images = np.concatenate([images, data[b\"data\"]], axis=0)  # add more images to the existing numpy array\n","        #    labels = labels + data_dict[b\"labels\"]  # add more labels to the existing list\n","        if train:\n","          pass\n","        else:\n","          pass\n","\n","    def __getitem__(self, index) -> Tuple[np.array, np.array]:\n","        ...\n","    \n","    def __len__(self) -> int:\n","        ..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xt7HZELVSK47"},"outputs":[],"source":["# This is the test code for the class CustomDataset.\n","\n","def test_custom_dataset():\n","    ds = CustomDataset(train=True)\n","    print(f\"Dataset has {len(ds)} examples\")\n","    assert len(ds) == 50000, f\"Expect the training set to have 50000 examples.\"\n","    ds = CustomDataset(train=False)\n","    assert len(ds) == 10000, f\"Expect the validation set to have 10000 examples.\"\n","    first_example = ds[0]\n","    print(f\"The first example is a {type(first_example)} with {len(first_example)} elements\")\n","    image, label = first_example\n","    print(f\"The first example has an image of shape {image.shape} and label {label}\")\n","    assert len(image.shape) == 3\n","    assert (label >= 0) and (label < 10), f\"Label {label} is not in [0, 10)\"\n","    print(\"Test passed!\")\n","\n","test_custom_dataset()"]},{"cell_type":"markdown","metadata":{"id":"FklkowDOSK47"},"source":["If the tests works, congratulations! You have completed the first step of the project. You have implemented a dataset class similar to `torchvision.datasets.CIFAR10`.\n","\n","\n","## Step 2: Visualize the image data\n","\n","However, passing the unit tests may not be enough. The content of the image may not make sense even if the shape is correct, depending on how the reshaping of numpy arrays is done.\n","\n","In the next cells, display several images from the dataset together with the label. Visually check the image and the label. A helper function is provided."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Z4l3ROgSK48"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","\n","import numpy as np\n","\n","def display_image_with_label(image: np.array, label: int):\n","    if image.shape[0] == 3:\n","        image = image.transpose(1, 2, 0)\n","    plt.imshow(image)\n","    plt.title(f\"Label: {label}\")\n","    plt.show()\n","\n","# TODO: add code to the next cells to display at least 2 images from CustomDataset.\n","# You can use one cell for each image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GEcRzeJUSK48"},"outputs":[],"source":["# TODO: display the first image and label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZC_7vbgqSK48"},"outputs":[],"source":["# TODO: display the second image and label"]},{"cell_type":"markdown","metadata":{"id":"0UPA2sT_SK48"},"source":["\n","## Step 3: Create a data loader\n","\n","A data loader is a class that can be used to load batches of data. It provides a way to iterate over the `Dataset`, returning a batch of data at each iteration.\n","\n","For PyTorch, we strongly recommend using the [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) class to load the data. It has a lot of built-in functionalities to handle efficient concurrent loading of data that you don't need to implement from scratch. In our experience, it is rarely needed to implement a custom version of `DataLoader`. Getting familar with how to use a PyTorch `DataLoader` is usually enough.\n","\n","The figure below (source: {cite}`stevens2020learning`) shows the relationship between a `Dataset` and a `DataLoader`:\n","\n","![dataset and dataloader](https://drek4537l1klr.cloudfront.net/stevens2/Figures/CH07_F14_Stevens2_GS.png)\n","\n","**Your task**: Fill in the missing code in the next cell, so that it can pass the test that follows."]},{"cell_type":"code","execution_count":99,"metadata":{"executionInfo":{"elapsed":154,"status":"ok","timestamp":1660185951422,"user":{"displayName":"Zhangzhang Si","userId":"05784349039024700350"},"user_tz":300},"id":"-B7gdFFLSK48"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 16\n","\n","# TODO: fill in the code to create a data loader with a batch size of 16.\n","data_loader = DataLoader(...)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iofFsZxcSK48"},"outputs":[],"source":["def test_data_loader():\n","    for batch in data_loader:\n","        images, labels = batch\n","        assert images.shape[0] == batch_size, f\"Expecting a batch of {batch_size} images\"\n","        assert len(images.shape) == 4, f\"shape is {images.shape} for the image batch\"\n","        assert len(labels) == batch_size, f\"Expecting a batch of {batch_size} labels\"\n","        print(\"The test is passed!\")\n","        break\n","\n","\n","test_data_loader()"]},{"cell_type":"markdown","metadata":{"id":"W0eMF16wSK49"},"source":["### Display images in a grid using `matplotlib`\n","\n","You can also display multiple images in one figure. This way you can visualize a batch of images easily. Below is a function and snippet to start with. You may need to transpose the image for display purpose.\n","\n","```\n","def show_images(images, labels: list = None, ncols: int = 8):\n","    nrows = (len(images) + ncols - 1) // ncols\n","    plt.figure(figsize=(2 * ncols, 2 * nrows))\n","    for i in range(len(images)):\n","        plt.subplot(nrows, ncols, i + 1)\n","        plt.imshow(images[i])\n","        if labels is not None:\n","          plt.title(labels[i])\n","        plt.axis('off')\n","\n","\n","batch = next(iter(data_loader))\n","images, labels = batch\n","```"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1660254937181,"user":{"displayName":"Zhangzhang Si","userId":"05784349039024700350"},"user_tz":300},"id":"VzvhMlozxdUU"},"outputs":[],"source":["# TODO: visualize a batch of images"]},{"cell_type":"markdown","metadata":{"id":"o3xQ9JfXSK49"},"source":["## Step 4 (optional): Writing unit tests for your dataset class\n","\n","To make sure your dataset is feeding the right data to the model, visualization is helpful, but unit tests can make certain checks more efficient.\n","\n","You may have noticed, in previous steps unit tests such as `test_custom_dataset` are already used to check the correctness of your implementation.\n","\n","The following types of unit tests can be written against a dataset class:\n","\n","- Tests that check the functionality of the class (e.g. calling `len(dataset)` does not raise an error).\n","- Tests that check the type and shape of the data returned by the class.\n","- Tests that check the content of the data returned by the class.\n","\n","Below is an example unit test that checks if the shape of the image is \"channels-first\" (3, height, width) rather than \"channels-last\" (height, width, 3). PyTorch expects the image to be in \"channels-first\" format, while Tensorflow expects it to be \"channels-last\".\n","\n","**Your task**: Fill in the missing code in unit test. Make necesssary changes to your dataset class to pass the test. Can you think of other tests that can answer questions about the dataset? For example, can you write a test about the maximum pixel intensity of this dataset?\n","\n"]},{"cell_type":"code","execution_count":102,"metadata":{"executionInfo":{"elapsed":462,"status":"ok","timestamp":1660186157748,"user":{"displayName":"Zhangzhang Si","userId":"05784349039024700350"},"user_tz":300},"id":"ZAzu52BfSK49"},"outputs":[],"source":["def test_custom_dataset_returns_images_with_channels_first():\n","    \"\"\"Check the shape of the image, especially the channels axis.\n","    \"\"\"\n","    # TODO: fill in.\n","    pass\n","\n","\n","test_custom_dataset_returns_images_with_channels_first()"]},{"cell_type":"markdown","metadata":{"id":"un6B-xkMSK49"},"source":["**Congratulations!** You have completed the first project of this course.\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"p1_dataset.ipynb","provenance":[{"file_id":"https://github.com/kungfuai/kungfuu-computer-vision/blob/main/course1-image-classification/p1_dataset.ipynb","timestamp":1660179267910}]},"kernelspec":{"display_name":"Python 3.8.13 ('kungfuu')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"3b6480ec1b87656350dd6ddf61559e3fd9d4b0710686fddab793795a6111e81d"}}},"nbformat":4,"nbformat_minor":0}

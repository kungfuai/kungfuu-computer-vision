{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Preparing an image dataset for model training\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "- Implement a [map-style Dataset class](https://pytorch.org/docs/stable/data.html#map-style-datasets).\n",
    "- Implement a [data loader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) that directly feeds data into model training.\n",
    "- Quality check your data, served through dataset class.\n",
    "\n",
    "**Acceptance criteria:**\n",
    "\n",
    "- The Dataset class should implement `__getitem__`  and `__len__` methods, where `__getitem__` should return a training example, which is a tuple of (image, label).\n",
    "- The data loader should be iterable and returns batches of examples.\n",
    "- In a notebook, present example images, labels and ensure correct shapes by visual inspection.\n",
    "\n",
    "## Step 1: Create a Dataset class\n",
    "\n",
    "One of the first things you may need to do in a practical project is to create a custom dataset class. As a start, let us use CIFAR10 raw data as an example to create one. First, we need to download the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xzf cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the downloaded raw data and folder structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 363752\n",
      "-rw-r--r--  1 zzsi  staff    88B Jun  4  2009 readme.html\n",
      "-rw-r--r--  1 zzsi  staff   158B Mar 30  2009 batches.meta\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 data_batch_4\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 data_batch_1\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 data_batch_5\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 data_batch_2\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 data_batch_3\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 test_batch\n"
     ]
    }
   ],
   "source": [
    "!ls -lht cifar-10-batches-py/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object.\n",
    "\n",
    "Loaded using the `unpickle` method provided below, each of the batch files contains a dictionary with the following elements:\n",
    "\n",
    "*data* -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "*labels* -- a list of 10000 numbers in the range 0-9. \n",
    "\n",
    "**Your task**: Fill in the missing code in the next cell, so that it can pass the test that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "\n",
    "def reshape_numpy_image(one_numpy_image):\n",
    "    # TODO: which of the following is correct?\n",
    "    shape_with_channels_last = (32, 32, 3)\n",
    "    shape_with_channels_first = (3, 32, 32)\n",
    "    return one_numpy_image.reshape(*shape_with_channels_last)\n",
    "\n",
    "\n",
    "class CustomDataset:\n",
    "    def __getitem__(self, index):\n",
    "        ...\n",
    "    \n",
    "    def __len__(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the test code for the class CustomDataset.\n",
    "\n",
    "def test_custom_dataset():\n",
    "    ds = CustomDataset()\n",
    "    print(f\"Dataset has {len(ds)} examples\")\n",
    "    assert len(ds) > 0, f\"Your dataset has no examples\"\n",
    "    first_example = ds[0]\n",
    "    print(f\"The first example is a {type(first_example)} with {len(first_example)} elements\")\n",
    "    image, label = first_example\n",
    "    print(f\"The first example has an image of shape {image.shape} and label {label}\")\n",
    "    assert len(image.shape) == 3\n",
    "    assert (label >= 0) and (label < 10), f\"Label {label} is not in [0, 10)\"\n",
    "\n",
    "test_custom_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it works, congratulations! You have completed the first step of the project.\n",
    "\n",
    "\n",
    "## Step 2: Visualize the image data\n",
    "\n",
    "However, passing the unit tests may not be enough. The content of the image may not make sense even if the shape is correct, depending on how the reshaping of numpy arrays is done.\n",
    "\n",
    "In the next cells, display several images from the dataset together with the label. Visually check the image and the label. A helper function is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def display_image_with_label(image: np.array, label: int):\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "# TODO: add code to display at least 2 images from CustomDataset.\n",
    "# You can use one cell for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: display the first image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: display the second image and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional practice: visualizing images in html\n",
    "\n",
    "You can also save images as files, and then use the [`display`](https://ipython.org/ipython-doc/3/interactive/html/widgets.html#widgets.display) function to display them in an IPython notebook.\n",
    "\n",
    "Example code to save a numpy array as an image:\n",
    "\n",
    "```{python}\n",
    "from PIL import Image\n",
    "\n",
    "Image.fromarray(image).save('image.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 3: Create a data loader\n",
    "\n",
    "A data loader is a class that can be used to load batches of data. It is a simple wrapper around a dataset that provides a way to iterate over the dataset, returning a batch of data at each iteration.\n",
    "\n",
    "For PyTorch, we strongly recommend using the [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) class to load the data. It has a lot of built-in functionalities to handle efficient loading of data that you don't need to implement from scratch. In our experience, it is rarely needed to implement a custom version of `DataLoader`. Getting familar with how to use a PyTorch `DataLoader` is usually enough.\n",
    "\n",
    "**Your task**: Fill in the missing code in the next cell, so that it can pass the test that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "# TODO: fill in the code to create a data loader with a batch size of 8.\n",
    "data_loader = DataLoader(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_loader():\n",
    "    for batch in data_loader:\n",
    "        images, labels = batch\n",
    "        assert images.shape[0] == batch_size, f\"Expecting a batch of {batch_size} images\"\n",
    "        assert len(labels) == batch_size, f\"Expecting a batch of {batch_size} labels\"\n",
    "        break\n",
    "\n",
    "\n",
    "test_data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional practice: display images in a grid using `matplotlib`\n",
    "\n",
    "You can also display multiple images in one figure. This way you can visualize a batch of images easily. Below is a function to start with.\n",
    "\n",
    "```\n",
    "def show_images(images, ncols=8):\n",
    "    nrows = (len(images) + ncols - 1) // ncols\n",
    "    plt.figure(figsize=(2 * ncols, 2 * nrows))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(nrows, ncols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 (optional): Writing unit tests for your dataset class\n",
    "\n",
    "To make sure your dataset is feeding the right data to the model, visualization is helpful, but unit tests can make certain checks more efficient.\n",
    "\n",
    "You may have noticed, in previous steps unit tests such as `test_custom_dataset` are already used to check the correctness of your implementation.\n",
    "\n",
    "The following types of unit tests can be written against a dataset class:\n",
    "\n",
    "- Tests that check the functionality of the class (e.g. calling `len(dataset)` does not raise an error).\n",
    "- Tests that check the type and shape of the data returned by the class.\n",
    "- Tests that check the content of the data returned by the class.\n",
    "\n",
    "Below is an example unit test that checks if the shape of the image is \"channels-first\" (3, height, width) rather than \"channels-last\" (height, width, 3). PyTorch expects the image to be in \"channels-first\" format, while Tensorflow expects it to be \"channels-last\".\n",
    "\n",
    "**Your task**: Fill in the missing code in unit test. Make necesssary changes to your dataset class to pass the test. Can you think of other tests that can answer questions about the dataset? For example, can you write a test about the maximum pixel intensity of this dataset?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_dataset_returns_images_with_channels_first():\n",
    "    \"\"\"Check the shape of the image, especially the channels axis.\n",
    "    \"\"\"\n",
    "    # TODO: fill in.\n",
    "    pass\n",
    "\n",
    "\n",
    "test_custom_dataset_returns_images_with_channels_first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have completed the first project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kungfuu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b6480ec1b87656350dd6ddf61559e3fd9d4b0710686fddab793795a6111e81d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Preparing an image dataset for model training\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "- Using PyTorch, implement a [map-style Dataset class](https://pytorch.org/docs/stable/data.html#map-style-datasets).\n",
    "- Implement a [data loader] (https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) that directly feeds data into model training.\n",
    "- Quality check your data, served through dataset class.\n",
    "\n",
    "**Acceptance criteria:**\n",
    "\n",
    "- The Dataset class should implement `__getitem__`  and `__len__` methods, where `__getitem__` should return a training example, which is a tuple of (image, label).\n",
    "- The data loader should be iterable and returns batches of examples.\n",
    "- In a notebook, present example images, labels and ensure correct shapes.\n",
    "\n",
    "## Step 1: Create a Dataset class\n",
    "\n",
    "For a practical project, the dataset is usually custom rather than a standard public dataset, so you would need to write your own dataset class. As a start, let us use CIFAR10 raw data as an example to create one. First, we need to download the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xzf cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the downloaded raw data and folder structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 363752\n",
      "-rw-r--r--  1 zzsi  staff    88B Jun  4  2009 readme.html\n",
      "-rw-r--r--  1 zzsi  staff   158B Mar 30  2009 batches.meta\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 data_batch_4\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 data_batch_1\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 data_batch_5\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 data_batch_2\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 data_batch_3\n",
      "-rw-r--r--  1 zzsi  staff    30M Mar 30  2009 test_batch\n"
     ]
    }
   ],
   "source": [
    "!ls -lht cifar-10-batches-py/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object.\n",
    "\n",
    "Loaded using the `unpickle` method provided below, each of the batch files contains a dictionary with the following elements:\n",
    "\n",
    "*data* -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "*labels* -- a list of 10000 numbers in the range 0-9. \n",
    "\n",
    "**Your task**: Fill in the missing code in the next cell, so that it can pass the test that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Please add your code here.\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "\n",
    "class CustomDataset:\n",
    "    def __getitem__(self, index):\n",
    "        ...\n",
    "    \n",
    "    def __len__(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the test code for the class CustomDataset.\n",
    "\n",
    "def test_custom_dataset():\n",
    "    ds = CustomDataset()\n",
    "    print(f\"Dataset has {len(ds)} examples\")\n",
    "    first_example = ds[0]\n",
    "    print(f\"The first example is a {type(first_example)} with {len(first_example)} elements\")\n",
    "    image, label = first_example\n",
    "    print(f\"The first example has an image of shape {image.shape} and label {label}\")\n",
    "\n",
    "test_custom_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it works, congratulations! You have completed the first step of the project.\n",
    "\n",
    "## Step 2: Create a data loader\n",
    "\n",
    "A data loader is a class that can be used to load batches of data. It is a simple wrapper around a dataset that provides a way to iterate over the dataset, returning a batch of data at each iteration.\n",
    "\n",
    "For PyTorch, we can use the [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) class to load the data.\n",
    "\n",
    "**Your task**: Fill in the missing code in the next cell, so that it can pass the test that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fill in the code to create a data loader with a batch size of 8.\n",
    "\n",
    "batch_size = 8\n",
    "data_loader = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_loader():\n",
    "    for batch in data_loader:\n",
    "        images, labels = batch\n",
    "        assert images.shape[0] == batch_size, f\"Expecting a batch of {batch_size} images\"\n",
    "        assert len(labels) == batch_size, f\"Expecting a batch of {batch_size} labels\"\n",
    "        break\n",
    "\n",
    "\n",
    "test_data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize the data\n",
    "\n",
    "In the next cells, display several images from the dataset together with the label. Visually check the image and the label. A helper function is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def display_image_with_label(im, label):\n",
    "    plt.imshow(im)\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "# TODO: add code to display at least 3 images from CustomDataset.\n",
    "# You can use one cell for each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 (optional): Writing unit tests for your dataset class\n",
    "\n",
    "To make sure your dataset is feeding the right data to the model, visualization is helpful, but unit tests can make certain checks more efficient.\n",
    "\n",
    "You may have noticed, in previous steps unit tests such as `test_custom_dataset` are already used to check the correctness of your implementation.\n",
    "\n",
    "The following types of unit tests can be written against a dataset class:\n",
    "\n",
    "- Tests that check the functionality of the class (e.g. calling `len(dataset)` does not raise an error).\n",
    "- Tests that check the type and shape of the data returned by the class.\n",
    "- Tests that check the content of the data returned by the class.\n",
    "\n",
    "Below is an example unit test that checks if the shape of the image is \"channels-first\" (3, height, width) rather than \"channels-last\" (height, width, 3). PyTorch expects the image to be in \"channels-first\" format, while Tensorflow expects it to be \"channels-last\".\n",
    "\n",
    "**Your task**: Fill in the missing code in unit test. Make necesssary changes to your dataset class to pass the test. Can you think of other tests that can answer questions about the dataset? For example, can you write a test about the maximum pixel intensity of this dataset?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_dataset_returns_images_with_channels_first():\n",
    "    \"\"\"Check the shape of the image, especially the channels axis.\n",
    "    \"\"\"\n",
    "    # TODO: fill in.\n",
    "    pass\n",
    "\n",
    "\n",
    "test_custom_dataset_returns_images_with_channels_first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have completed the first project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kungfuu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b6480ec1b87656350dd6ddf61559e3fd9d4b0710686fddab793795a6111e81d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

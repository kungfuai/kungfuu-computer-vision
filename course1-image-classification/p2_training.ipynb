{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: A minimal model training experiment\n",
    "\n",
    "**Goal**:\n",
    "\n",
    "- Create a [PyTorch LightningModule](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html) named `ImageClassifier` that holds a convolutional network with ResNet18 backbone.\n",
    "- Learn to adapt the dataset class to be compatible with the model.\n",
    "- Train a model using the dataset class and the dataloader created in the previous object.\n",
    "- Understand the concept of fine-tuning and the benefits of starting from a pre-trained model.\n",
    "- Understand the benefits and options of a dataloader.\n",
    "- Learn how to visualize model predictions.\n",
    "\n",
    "**Acceptance Criteria**:\n",
    "\n",
    "- Implement a test that checks a simple `ImageClassifier` can be predict on an image that has the correct shape.\n",
    "- The `ImageClassifier` can be trained on the CIFAR10 dataset, showing decreasing loss and accuracy for several epochs.\n",
    "\n",
    "## Step 1: Create a model using `LightningModule`\n",
    "\n",
    "`LightningModule` is a convenient and structured way to implement a PyTorch model, as well as its training and validation behaviors. For more information, please refer to the [documentation](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html) for `LightningModule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.12.0\n",
      "  Using cached torch-1.12.0-cp38-none-macosx_10_9_x86_64.whl (137.6 MB)\n",
      "Collecting torchvision==0.13.0\n",
      "  Using cached torchvision-0.13.0-cp38-cp38-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: requests in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from torchvision==0.13.0) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from torchvision==0.13.0) (1.23.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from torchvision==0.13.0) (9.2.0)\n",
      "Collecting protobuf<=3.20.1\n",
      "  Downloading protobuf-3.20.1-cp38-cp38-macosx_10_9_x86_64.whl (962 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.3/962.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from pytorch-lightning) (21.3)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from pytorch-lightning) (6.0)\n",
      "Collecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-0.9.2-py3-none-any.whl (419 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.7/419.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.57.0\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.1-cp38-cp38-macosx_10_9_x86_64.whl (574 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp38-cp38-macosx_10_10_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.9.0-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.8/167.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning) (61.2.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<=3.20.1\n",
      "  Using cached protobuf-3.19.4-cp38-cp38-macosx_10_9_x86_64.whl (961 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from requests->torchvision==0.13.0) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from requests->torchvision==0.13.0) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from requests->torchvision==0.13.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from requests->torchvision==0.13.0) (3.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (1.16.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.12.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.7.2-cp38-cp38-macosx_10_9_x86_64.whl (121 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.0-cp38-cp38-macosx_10_9_x86_64.whl (36 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp38-cp38-macosx_10_9_x86_64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.5/151.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, werkzeug, typing-extensions, tqdm, tensorboard-data-server, rsa, pyDeprecate, pyasn1-modules, protobuf, oauthlib, multidict, grpcio, fsspec, frozenlist, cachetools, async-timeout, absl-py, yarl, torch, requests-oauthlib, markdown, google-auth, aiosignal, torchvision, torchmetrics, google-auth-oauthlib, aiohttp, tensorboard, pytorch-lightning\n",
      "Successfully installed absl-py-1.1.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 cachetools-5.2.0 frozenlist-1.3.0 fsspec-2022.5.0 google-auth-2.9.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 markdown-3.3.7 multidict-6.0.2 oauthlib-3.2.0 protobuf-3.19.4 pyDeprecate-0.3.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch-lightning-1.6.4 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torch-1.12.0 torchmetrics-0.9.2 torchvision-0.13.0 tqdm-4.64.0 typing-extensions-4.3.0 werkzeug-2.1.2 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "# Install the dependencies:\n",
    "!pip install torch==1.12.0 torchvision==0.13.0 pytorch-lightning==1.6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = resnet18(num_classes=10, weights=None)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the forward path of the model\n",
    "\n",
    "As a trainable function, the model is callable. The model's forward path (as defined in `forward()`) is the normal execution of the function. We can test this by passing an image to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert callable(model)  # is the model callable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a valid input?\n",
    "\n",
    "To test the forward path of the model, we need to pass a valid input. The input should be a tensor of shape `(b, 3, 32, 32)` where `b` is the batch size (an integer).\n",
    "\n",
    "**Your Task**: Fix the code below to pass the test.\n",
    "\n",
    "**Tips:** `torch.from_numpy()` can be used to convert a numpy array to a tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# TODO: The test is broken. Please fix it.\n",
    "def test_model_can_predict_on_a_random_image():\n",
    "    input_image = np.ones(shape=(3, 224, 224), dtype=np.float32)\n",
    "    output = model(input_image)  # run the model on the input image\n",
    "\n",
    "\n",
    "test_model_can_predict_on_a_random_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the dataset and data loader\n",
    "\n",
    "Please reuse the `CustomDataset` and dataloader from the previous object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy over the code from the previous project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training the model\n",
    "\n",
    "We can start adding the training behavior to the model. To train a model using backpropagation, we need to define a loss function, an optimizer and a training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = resnet18(num_classes=10, weights=None)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    def loss(self, y_hat, y):\n",
    "        return F.cross_entropy(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return {'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_training_step_works():\n",
    "    # TODO: Use the data loader to get a batch of data.\n",
    "    #    Then, call the `training_step` and assert that the return value is a dictionary that looks\n",
    "    #    like this: {'loss': 0.5}.\n",
    "    ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kungfuu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b6480ec1b87656350dd6ddf61559e3fd9d4b0710686fddab793795a6111e81d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

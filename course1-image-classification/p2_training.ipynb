{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: A minimal model training experiment\n",
    "\n",
    "**Goal**:\n",
    "\n",
    "- Create a [PyTorch LightningModule](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html) named `ImageClassifier` that holds a convolutional network with ResNet18 backbone.\n",
    "- Learn to adapt the dataset class to be compatible with the model.\n",
    "- Understand a minimal set of components of a model training pipeline: loss, optimizer, metrics, training loop.\n",
    "- Assemble the components to train a model using the dataset class and the dataloader created in the previous object.\n",
    "- Learn how to visualize model predictions.\n",
    "- Understand the concept of fine-tuning and the benefits of starting from a pre-trained model. (may move to the next project)\n",
    "- Understand the benefits and options of a dataloader. (may move to the next project)\n",
    "\n",
    "**Acceptance Criteria**:\n",
    "\n",
    "- Implement a test that checks a simple `ImageClassifier` can be predict on an image that has the correct shape.\n",
    "- The `ImageClassifier` can be trained on the CIFAR10 dataset, showing decreasing loss and accuracy for several epochs.\n",
    "\n",
    "## Step 1: Create a model using `LightningModule`\n",
    "\n",
    "`LightningModule` is a convenient and structured way to implement a PyTorch model, as well as its training and validation behaviors. For more information, please refer to the [documentation](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html) for `LightningModule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.12.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (1.12.0)\n",
      "Requirement already satisfied: torchvision==0.13.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (0.13.0)\n",
      "Requirement already satisfied: pytorch-lightning==1.6.4 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (1.6.4)\n",
      "Requirement already satisfied: torchmetrics in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from torch==1.12.0) (4.3.0)\n",
      "Requirement already satisfied: requests in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from torchvision==0.13.0) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from torchvision==0.13.0) (1.23.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from torchvision==0.13.0) (9.2.0)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from pytorch-lightning==1.6.4) (2022.5.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from pytorch-lightning==1.6.4) (4.64.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from pytorch-lightning==1.6.4) (21.3)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from pytorch-lightning==1.6.4) (3.19.4)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from pytorch-lightning==1.6.4) (2.9.1)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from pytorch-lightning==1.6.4) (0.3.2)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from pytorch-lightning==1.6.4) (6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from packaging>=17.0->pytorch-lightning==1.6.4) (3.0.9)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (3.3.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (2.1.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (2.9.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (61.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (1.8.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (1.47.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.37.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from requests->torchvision==0.13.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from requests->torchvision==0.13.0) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from requests->torchvision==0.13.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from requests->torchvision==0.13.0) (2022.6.15)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (4.12.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.4) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/zzsi/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.6.4) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Install the dependencies:\n",
    "!pip install torch==1.12.0 torchvision==0.13.0 pytorch-lightning==1.6.4 torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = resnet18(num_classes=10, weights=None)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the forward path of the model\n",
    "\n",
    "As a trainable function, the model is callable. The model's forward path (as defined in `forward()`) is the normal execution of the function. We can test this by passing an image to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert callable(model)  # is the model callable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a valid input?\n",
    "\n",
    "To test the forward path of the model, we need to pass a valid input. The input should be a tensor of shape `(b, 3, 32, 32)` where `b` is the batch size (an integer).\n",
    "\n",
    "**Your Task**: Fix the code below to pass the test.\n",
    "\n",
    "**Tips:** `torch.from_numpy()` can be used to convert a numpy array to a tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# TODO: The test is broken. Please fix it.\n",
    "def test_model_can_predict_on_a_random_image():\n",
    "    input_image = np.ones(shape=(3, 224, 224), dtype=np.float32)\n",
    "    output = model(input_image)  # run the model on the input image\n",
    "    assert output.shape == (1, 10)  # is the output shape correct?\n",
    "\n",
    "\n",
    "test_model_can_predict_on_a_random_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare the dataset and data loader\n",
    "\n",
    "Please reuse the `CustomDataset` and dataloader from the previous object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy over the code from the previous project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training the model\n",
    "\n",
    "#### Loss\n",
    "\n",
    "A loss is a function that takes the model's output and the ground truth as input and returns a scalar value. The loss is used as the feedback mechantism to optimize the model.\n",
    "\n",
    "For classification, the loss is typically the cross-entropy. Use `torch.nn.functional.cross_entropy` when the model output are logits or `torch.nn.functional.nll_loss` when the outputs are probabilities (a.k.a. softmax)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Task**: The following code almost works but there is a bug related to data type. Please fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/zzsi/projects/kungfu/kungfuu-computer-vision/course1-image-classification/p2_training.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zzsi/projects/kungfu/kungfuu-computer-vision/course1-image-classification/p2_training.ipynb#ch0000020?line=3'>4</a>\u001b[0m y_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39marray([[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m5\u001b[39m]], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/zzsi/projects/kungfu/kungfuu-computer-vision/course1-image-classification/p2_training.ipynb#ch0000020?line=4'>5</a>\u001b[0m y_true \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/zzsi/projects/kungfu/kungfuu-computer-vision/course1-image-classification/p2_training.ipynb#ch0000020?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(F\u001b[39m.\u001b[39;49mcross_entropy(y_pred, y_true))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/kungfuu/lib/python3.8/site-packages/torch/nn/functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "# To simplify the code, assume there are 3 image classes.\n",
    "y_pred = torch.from_numpy(np.array([[0, 0, 5]], dtype=np.float32))\n",
    "y_true = torch.from_numpy(np.array([1], dtype=np.float32))\n",
    "print(F.cross_entropy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Task**: Can you make the loss lower? Try changing `y_pred` in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change y_pred to make the loss lower.\n",
    "y_pred = torch.from_numpy(np.array([[0, 0, 5]], dtype=np.float32))\n",
    "y_true = torch.from_numpy(np.array([1], dtype=int))\n",
    "print(F.cross_entropy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer\n",
    "\n",
    "The gradient over model parameters (a.k.a. model weights) is computed of the loss function, and informs how the model parameters should be updated. The specifics of how the model is updated is handled by an optimizer.\n",
    "\n",
    "An optimizer can be created by passing the model parameters (`model.parameters()`) to the optimizer constructor, as well as learning rate, momentum, and other hyper-parameters. Below is a minimal example of using an optimizer.\n",
    "\n",
    "```{python}\n",
    "for input, target in dataset:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "When using `LightningModule`, this is taken care of under the hood (pseudo-code):\n",
    "\n",
    "```\n",
    "# put model in train mode and enable gradient calculation\n",
    "model.train()\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "outs = []\n",
    "for batch_idx, batch in enumerate(train_dataloader):\n",
    "    loss = training_step(batch, batch_idx)\n",
    "    outs.append(loss.detach())\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "```\n",
    "\n",
    "For more details, please refer to [the documentation for PyTorch optimizers](https://pytorch.org/docs/stable/optim.html) and [the documentation for `LightningModule`](https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Step\n",
    "\n",
    "We can start specifying the training behavior to the model by adding the `training_step` method in the `ImageClassifier` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = resnet18(num_classes=10, weights=None)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    def loss(self, y_hat, y):\n",
    "        return F.cross_entropy(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your task**: Implement the following unit test. Use the data loader to get a batch of data.\n",
    "Then, call the `training_step` and assert that the return value is a dictionary that looks\n",
    "like this: `{'loss': 0.5}`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_training_step_works():\n",
    "    # TODO: Use the data loader to get a batch of data.\n",
    "    #    Then, call the `training_step` and assert that the return value is a dictionary that looks\n",
    "    #    like this: {'loss': 0.5}.\n",
    "    ...\n",
    "\n",
    "\n",
    "test_training_step_works()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "A metric is a function that takes the model's output and the ground truth as input and returns a scalar value. The metric is used to evaluate the model's performance. It is mainly used to monitor the training progress and does not directly influence the model's training behavior. However, it can influence model selection and early stopping.\n",
    "\n",
    "For classification, the metric is typically the accuracy. We will use `torchmetrics.Accuracy` in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Again, for simplicity, assume there are only 3 imge classes.\n",
    "y_pred = torch.from_numpy(np.array([[0, 0, 5], [2, -1, 1]], dtype=np.float32))\n",
    "# The following line is optional and shouldn't change the result.\n",
    "# y_pred = F.softmax(y_pred, dim=1)\n",
    "y_true = torch.from_numpy(np.array([1, 0], dtype=int))\n",
    "acc = Accuracy(num_classes=3)\n",
    "acc.update(y_pred, y_true)\n",
    "print(\"Accuracy:\", acc.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "A training loop manages the training process that iteratively passes batches of training examples to the model and running the training step. \n",
    "\n",
    "The training steps are organized into \"epochs\", where an epoch can be a single pass through the entire training dataset, or it can be simply a predefined number of training steps. At the end of an epoch, the model is used predict on the validation dataset and calculate accuracy metrics.\n",
    "\n",
    "To do this, we need to add `validation_step` and `validation_epoch_end` methods and accuracy metrics to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "\n",
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = resnet18(num_classes=10, weights=None)\n",
    "        self.val_accuracy = Accuracy(num_classes=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    def loss(self, y_hat, y):\n",
    "        return F.cross_entropy(y_hat, y)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        self.val_accuracy.update(preds=y_hat, target=y)\n",
    "        val_loss = self.loss(y_hat, y)\n",
    "        return val_loss\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x for x in outputs]).mean()\n",
    "        avg_acc = self.val_accuracy.compute()\n",
    "        self.log('val_loss', avg_loss, prog_bar=True)\n",
    "        self.log('val_acc', avg_acc, prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model predictions\n",
    "\n",
    "Having loss going down and accuracy going up is nice. But to have the peace of mind that the model is working and is indeed better, it is helpful to visualize the model's predictions.\n",
    "\n",
    "**Your Task**: Complete the following cells to visualize the model's predictions.\n",
    "\n",
    "First, visualize predictions from a randomly initialized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: call the un-trained model to predict on a few images from the validation set.\n",
    "#   Use the skill learned in project 1 to display a batch of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, take the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: call the trained model to predict on a few images from the validation set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kungfuu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b6480ec1b87656350dd6ddf61559e3fd9d4b0710686fddab793795a6111e81d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
